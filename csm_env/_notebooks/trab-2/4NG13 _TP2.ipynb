{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "double-syndicate",
   "metadata": {},
   "source": [
    "<div>\n",
    "     <div>\n",
    "        <img src=\"./report/isel_logo.png\" width=\"400\" height=\"400\" align=\"left\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <h2>Área Departamental de Engenharia de Eletrónica e Telecomunicações e de Computadores</h2>\n",
    "        <p>Trabalho prático 2</p>\n",
    "        <p>Autor:\t44598\tAndré L. A. Q. de Oliveira</p>\n",
    "        <p>Unidade Curricular Compressão de Sinais Multimédia</p>\n",
    "        <p>Professor: André Lourenço</p>\n",
    "        <p>09 - Maio - 2021</p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-london",
   "metadata": {},
   "source": [
    "### <a id=\"index\"></a>\n",
    "\n",
    "# Index\n",
    "- [Codificação de Huffman](#codificacao_huffman)\n",
    "- [I/O Utilities](#io_utilities)\n",
    "    - [pad_bits](#pad_bits)\n",
    "    - [to_binary_list](#to_binary_list)\n",
    "    - [InputBitReader](#input_bit_reader)\n",
    "- [Tabela de Huffman](#tabela_huffman)\n",
    "    - [get_symbol_frequency](#get_symbol_frequency)\n",
    "    - [huff_node](#huff_node)\n",
    "    - [create_huff_tree](#create_huff_tree)\n",
    "    - [huff_tree_encode](#huff_tree_encode)\n",
    "    - [huff_tree_decode](#huff_tree_decode)\n",
    "    - [huff_tree2huff_dictionary](#huff_tree2huff_dictionary)\n",
    "    - [gen_huff_table](#gen_huff_table)\n",
    "- [Codificador de Huffman](#codificador_huffman)\n",
    "    - [encode_huff](#encode_huff)\n",
    "- [Descodificador de Huffman](#descodificador_huffman)\n",
    "    - [decode_huff](#decode_huff)\n",
    "- [Escrever para ficheiro](#escrever_ficheiro)\n",
    "    - [write2file](#write2file)\n",
    "- [Ler ficheiro](#ler_ficheiro)\n",
    "    - [read2array](#read2array)\n",
    "- [Testes](#testes)\n",
    "    - [a) gen_huff_table](#a)\n",
    "    - [b) calcular a eficiência](#b)\n",
    "    - [c) codificação da mensagem](#c)\n",
    "    - [d) gravar um ficheiro com a mensagem codificada](#d)\n",
    "    - [e) ler do ficheiro o conjunto de bits](#e)\n",
    "    - [f) descodificação da mensagem](#f)\n",
    "    - [g) comparar a mensagem descodificada com a original](#g)\n",
    "- [Conclusões](#conclusoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-dryer",
   "metadata": {},
   "source": [
    "<a id=\"codificacao_huffman\"></a>\n",
    "\n",
    "# Codificação de Huffman\n",
    "\n",
    "A codificação de Huffman é um método de compressão, desenvolvido em 1952 por  David A. Huffman, que usa as probabilidades de ocorrência dos símbolos nde um conjunto de dados a ser comprimido para determinar códigos binários de tamanho variável para cada símbolo.\n",
    "\n",
    "Uma árvore binária completa, chamada de árvore de Huffman é construída recursivamente a partir da junção dos dois símbolos de menor probabilidade, que são então somados em símbolos auxiliares que são depois recolocados no conjunto de símbolos. O processo termina quando todos os símbolos forem unidos em símbolos auxiliares, formando uma árvore binária. A árvore é então percorrida, atribuindo-se valores binários de 1 ou 0 para cada aresta, e os códigos são gerados a partir desse percurso.\n",
    "\n",
    "O resultado do algoritmo de Huffman pode ser visto como uma tabela de códigos de tamanho variável para codificar um símbolo. Os símbolos mais comuns são geralmente representados usando-se menos dígitos que os símbolos que aparecem com menos frequência.\n",
    "\n",
    "\n",
    "Para a string **\"go go gophers\"**, seria gerada a seguinte árvore de Huffman e respetiva tabela:\n",
    "\n",
    "![huff-table-example](./report/huff-table-example.PNG)\n",
    "\n",
    "A string seria codificada como: 000 001 111 000 001 111 000 001 010 011 100 101 110. Neste caso seriam utilizados três bits por caractere (em vez de oito bits por caractere como acontece no ASCII), a string **\"go go gophers\"** após codificação usaria um total de 39 bits em vez de 104 bits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-scratch",
   "metadata": {},
   "source": [
    "# Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharp-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "cwd = os.getcwd() # current work diretory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "massive-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.frombuffer('otorrinolaringologista'.encode('utf-8'), dtype='uint8')\n",
    "test2 = np.frombuffer('go go gophers'.encode('utf-8'), dtype='uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-welding",
   "metadata": {},
   "source": [
    "<a id=\"io_utilities\"></a>\n",
    "\n",
    "# I/O Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-operation",
   "metadata": {},
   "source": [
    "<a id=\"pad_bits\"></a>\n",
    "\n",
    "## pad_bits\n",
    "\n",
    "Extende o número de zeros a uma sequência de bits, para permitir codificação de tamanho fixo. Os zeros são adicionados nas posições de bit mais significantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simple-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_bits(bits, n):\n",
    "    # prefix string of bits with enough zeros to reach n digits\n",
    "    if isinstance(bits, np.ndarray):\n",
    "        if(n - len(bits) > 0):\n",
    "            return np.pad(bits, (n - len(bits), 0))\n",
    "        else:\n",
    "            return bits\n",
    "    else:\n",
    "        return ([0] * (n - len(bits)) + bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-designation",
   "metadata": {},
   "source": [
    "<a id=\"to_binary_list\"></a>\n",
    "\n",
    "## to_binary_list\n",
    "Converte um número inteiro na menor sequência de bits que o representa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unable-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary_list(n):\n",
    "    # convert integer into a list of bits\n",
    "    return [n] if (n <= 1) else to_binary_list(n >> 1) + [n & 1]\n",
    "\n",
    "    #return [int(i) for i in list('{0:8b}'.format(n))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powered-cream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(to_binary_list(320))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-private",
   "metadata": {},
   "source": [
    "<a id=\"input_bit_reader\"></a>\n",
    "\n",
    "## InputBitReader\n",
    "\n",
    "Para realizar compressão e descompressão com eficácia, é necessesário manipular os fluxos de dados como um fluxo de bits individuais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rational-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputBitReader(object): \n",
    "    def __init__(self, bit_seq): \n",
    "        self.bit_seq = bit_seq\n",
    "        self.size = len(bit_seq)\n",
    "        self.bits_read = 0\n",
    "        self.buffer = []\n",
    "\n",
    "    def read_bit(self):\n",
    "        if self.bits_read < self.size:\n",
    "            return self.read_bits(1)[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def read_bits(self, n):\n",
    "        self.__flush()\n",
    "        if self.bits_read < self.size:\n",
    "            self.buffer = pad_bits(self.bit_seq[self.bits_read:(self.bits_read + n)], n)\n",
    "            self.bits_read += n\n",
    "        return self.buffer\n",
    "    \n",
    "    def read_byte(self):\n",
    "        if self.bits_read < self.size:\n",
    "            byte = ''.join(list(map(str, self.read_bits(8))))\n",
    "            return int(byte, 2)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __flush(self):\n",
    "        self.buffer = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-commissioner",
   "metadata": {},
   "source": [
    " <a id=\"tabela_huffman\"></a>\n",
    "\n",
    "# Tabela de Huffman\n",
    "\n",
    "A codificação de Huffman é um método de compressão que usa as probabilidades de ocorrência dos símbolos no conjunto de dados a ser comprimido para determinar códigos de tamanho variável para cada símbolo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-reputation",
   "metadata": {},
   "source": [
    " <a id=\"get_symbol_frequency\"></a>\n",
    "\n",
    "## get_symbol_frequency\n",
    "\n",
    "\n",
    "Lê um ficheiro, símbolo a símbolo, e retorna um dicionário com par chave-valor : símbolo-frequência, onde cada símbolo terá como respondência a sua frequência no ficheiro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rolled-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return dicionary {symbol : frequency}\n",
    "def get_symbol_frequency(file):\n",
    "    d = dict()\n",
    "    for i in file:\n",
    "        d[i] = d.setdefault(i, 0) + 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-legend",
   "metadata": {},
   "source": [
    " <a id=\"huff_nome\"></a>\n",
    "\n",
    "## huff_node\n",
    "\n",
    "Classe que representa um nó de Huffman. Cada nó contêm a seguinte informação:\n",
    "* o símbolo\n",
    "* a frequência do símbolo\n",
    "* uma ligação para a esquerda e para a direita para os seus nós filhos\n",
    "* o valor de huffman atribuído quando o nó toma uma direção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "manual-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huffman Node\n",
    "class huff_node:\n",
    "    def __init__(self, symbol, freq, left = None, right = None):\n",
    "        # symbol\n",
    "        self.symbol = symbol\n",
    "        # frequency of symbol\n",
    "        self.freq = freq\n",
    "        # node left of current node\n",
    "        self.left = left\n",
    "        # node right of current node\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-mongolia",
   "metadata": {},
   "source": [
    " <a id=\"create_huff_tree\"></a>\n",
    "\n",
    "## create_huff_tree\n",
    "\n",
    "A árvore de Huffman é construída recursivamente a partir da junção dos dois símbolos de menor probabilidade, que são então somados em símbolos auxiliares e estes símbolos auxiliares recolocados no conjunto de símbolos. O processo termina quando todos os símbolos forem unidos em símbolos auxiliares, formando uma árvore binária.\n",
    "\n",
    "1. Com o valor de cada chave única presente no dicionário, são criados nós e colocados numa lista;\n",
    "2. São retirados os dois símbolos com menor frequência da lista, atribuindo-lhes o valor de 0 ou 1, e mergem-se esses dois símbolos num só, somando as suas freqûencias; \n",
    "3. O novo nó é adicionado a lista;\n",
    "4. O prodecimento repete-se até enquanto o número de nós for superior a 1;\n",
    "5. A função retorna o nó raiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cheap-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huff_tree(file):\n",
    "    dictionary = get_symbol_frequency(file)\n",
    "    \n",
    "    tree = []\n",
    "    for symb, freq in dictionary.items():\n",
    "        tree.append(huff_node(symb, freq))\n",
    "    \n",
    "    while len(tree) > 1:\n",
    "        tree = sorted(tree, key=lambda n: n.freq)\n",
    "        # pop the 2 smallest nodes\n",
    "        left  = tree.pop(0)\n",
    "        right = tree.pop(0)\n",
    "        # combine the 2 smallest nodes to create new node as their parent\n",
    "        new_node = huff_node(str(left.symbol) + str(right.symbol), left.freq + right.freq, left, right)\n",
    "        tree.append(new_node)\n",
    "        \n",
    "    return tree[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-owner",
   "metadata": {},
   "source": [
    "<a id=\"huff_tree2huff_dictionary\"></a>\n",
    "\n",
    "## huff_tree2huff_dictionary\n",
    "\n",
    "A partiz de uma árvore de Huffman gera um dicionário de Huffman. A árvore é percorrida, atribuindo-se valores binários de 1 ou 0 para cada nó, e os códigos são gerados a partir desse percurso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "constant-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huff_tree2huff_dictionary(node):\n",
    "    d = dict()\n",
    "    huff_tree2huff_dictionary_aux(node, d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "determined-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huff_tree2huff_dictionary_aux(node, dictionary, value = \"\"):\n",
    "    if(node.left):\n",
    "        huff_tree2huff_dictionary_aux(node.left, dictionary, value + \"0\")\n",
    "    if(node.right):\n",
    "        huff_tree2huff_dictionary_aux(node.right, dictionary, value + \"1\")\n",
    "    # if node is leaf\n",
    "    if(not node.left and not node.right):\n",
    "        dictionary[node.symbol] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affecting-greeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': '00', 'o': '01', 's': '100', ' ': '101', 'p': '1100', 'h': '1101', 'e': '1110', 'r': '1111'}\n"
     ]
    }
   ],
   "source": [
    "huffman_tree = create_huff_tree('go go gophers')\n",
    "d = huff_tree2huff_dictionary(huffman_tree)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-findings",
   "metadata": {},
   "source": [
    "<a id=\"huff_tree_encode\"></a>\n",
    "\n",
    "## huff_tree_encode\n",
    "\n",
    "Além de compactar um ficheiro, é necessário também armazenar um cabeçalho no arquivo compactado que será utilizado pelo programa de descompactação. Em suma, é necessário de alguam forma, armazenar a árvore utilizada para compactar o ficheiro original. Esta necessidade deve-se ao facto de o programa de descompressão precisa também dessa mesma árvore para decodificar os dados.\n",
    "\n",
    "Para armazenar a árvore de huffman no cabeçalho do ficheiro, recore-se a estratégia de pesquisa em árvore \"post-order transversel\", para assinalar cada nó visitado. Ao encontrar um nó folha, é escrito o valor 1, seguido pelo símbolo do nó folha. Ao encontrar um nó wue não seja folha, é escrito o valor um 0.\n",
    "\n",
    "Considerando a mesma string utilizanda anteriormente como exemplo, **\"go go gophers\"**, a informação do cabeçalho ficaria expressa sepla seguinte codificação: **\"1g1o01s1 01p1h01e1r0000\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smoking-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huff_tree_encode(node):\n",
    "    bits = []\n",
    "    huff_tree_encode_postorder(node, bits)\n",
    "    \n",
    "    huff_table = np.array([], dtype='uint8')\n",
    "    for bit in bits:\n",
    "        huff_table = np.append(huff_table, bit)\n",
    "    huff_table = np.packbits(huff_table)\n",
    "    \n",
    "    return huff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "identical-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huff_tree_encode_postorder(node, bits):\n",
    "    if (node.left):\n",
    "        huff_tree_encode_postorder(node.left, bits)\n",
    "    if (node.right):\n",
    "        huff_tree_encode_postorder(node.right, bits)\n",
    "    # if node is leaf\n",
    "    if (not node.left and not node.right):\n",
    "        bits.append(1)\n",
    "        bits.append(np.unpackbits(node.symbol))\n",
    "    else:\n",
    "        bits.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "involved-annotation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1g1o01s1 01p1h01e1r0000\n"
     ]
    }
   ],
   "source": [
    "# for example demonstration purposes\n",
    "def huff_tree_encode_postorder_ascii_example(node, symbols):\n",
    "    if (node.left):\n",
    "        huff_tree_encode_postorder_ascii_example(node.left, symbols)\n",
    "    if (node.right):\n",
    "        huff_tree_encode_postorder_ascii_example(node.right, symbols)\n",
    "    # if node is leaf\n",
    "    if (not node.left and not node.right):\n",
    "        symbols.append(1)\n",
    "        symbols.append(node.symbol)\n",
    "    else:\n",
    "        symbols.append(0)\n",
    "\n",
    "huffman_tree = create_huff_tree('go go gophers')\n",
    "huff_table = []\n",
    "huff_tree_encode_postorder_ascii_example(huffman_tree, huff_table)\n",
    "print(''.join(list(map(str,huff_table))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-integrity",
   "metadata": {},
   "source": [
    "<a id=\"huff_tree_decode\"></a>\n",
    "\n",
    "## huff_tree_decode\n",
    "\n",
    "A construção da árvore de Huffman a partir do cabeçalho, é realizada com recurso a um stack. A informação do cabeçalho deve ser lida bit a bit. Quando se lê um bit com o valor 1, significa que se está perante um nó do tipo folha, então é lido o próximo byte e coloca-se o símbolo no stack. Quando um bit com o valor 0 é lido, se a pilha contém apenas um elemento, então toda a árvore de Huffman está construída. Caso contrário, deve haver mais de um elemento na pilha, então são retirados os dois primeiros elementos da pilha. O primeiro elemento do stack é um novo nó direito, e o segundo elemento do stack é um novo nó esquerdo. Um o nó pai é criado com os filhos nó esquerdo e direito recém-criados, e é colocado depois no stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alleged-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huff_tree_decode(huff_table):\n",
    "    ibr = InputBitReader(np.unpackbits(huff_table))\n",
    "    tree = []\n",
    "    bits_read = 0\n",
    "    \n",
    "    while True:\n",
    "        if (ibr.read_bit() == 1):\n",
    "            byte = ibr.read_byte()\n",
    "            tree.append(huff_node(byte, 0, None, None))\n",
    "        else:\n",
    "            # if tree contains only 1 element, then its complete\n",
    "            if len(tree) == 1:\n",
    "                break\n",
    "            right = tree.pop()\n",
    "            left  = tree.pop()\n",
    "            tree.append(huff_node(0, 0, left, right))\n",
    "            \n",
    "    return tree[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-nation",
   "metadata": {},
   "source": [
    "<a id=\"gen_huff_table\"></a>\n",
    "\n",
    "## gen_huff_table\n",
    "\n",
    "Gere todas as chamadas das funções para gerar a tabela e o dicionário de Huffman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exotic-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_huff_table(file):\n",
    "    huff_tree = create_huff_tree(file)\n",
    "    huff_table = huff_tree_encode(huff_tree)\n",
    "    huff_dictionary = huff_tree2huff_dictionary(huff_tree)\n",
    "    return huff_table, huff_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "european-reference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary from encoded_table:\n",
      " {103: '00', 111: '01', 115: '100', 32: '101', 112: '1100', 104: '1101', 101: '1110', 114: '1111'} \n",
      "\n",
      "dictionary from decoded_table:\n",
      " {103: '00', 111: '01', 115: '100', 32: '101', 112: '1100', 104: '1101', 101: '1110', 114: '1111'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate huff table from \"go go gophers\" file\n",
    "encoded_table, huff_dictionary = gen_huff_table(test2)\n",
    "print(\"dictionary from encoded_table:\\n\", huff_dictionary, '\\n')\n",
    "\n",
    "# re-construct huffman tree from huff table\n",
    "decoded_huffman_tree = huff_tree_decode(encoded_table)\n",
    "# get huffman dictionary from huff table\n",
    "new_huff_dictionary = huff_tree2huff_dictionary(decoded_huffman_tree)\n",
    "print(\"dictionary from decoded_table:\\n\", new_huff_dictionary, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-absence",
   "metadata": {},
   "source": [
    " <a id=\"codificador_huffman\"></a>\n",
    "\n",
    "# Codificador de Huffman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-developer",
   "metadata": {},
   "source": [
    "<a id=\"encode_huff\"></a>\n",
    "\n",
    "## encode_huff\n",
    "\n",
    "A partir de um dicionário de huffman, codifica uma mensagem. A mensagem é lida símbolo a símbolo, e o valor do símbolo é substituído pela sequência de bits presente no dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sufficient-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_huff(file, huff_dictionary):\n",
    "    biq_seq = \"\"\n",
    "    for byte in file:\n",
    "        biq_seq += huff_dictionary[byte]\n",
    "    return list(map(int, biq_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cathedral-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# generate huff table from \"go go gophers\" file\n",
    "t, d = gen_huff_table(test2)\n",
    "# encode \"go go gophers\" file\n",
    "biq_seq = encode_huff(test2, d)\n",
    "print(biq_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-atlanta",
   "metadata": {},
   "source": [
    " <a id=\"descodificador_huffman\"></a>\n",
    "\n",
    "# Descodificador de Huffman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-banner",
   "metadata": {},
   "source": [
    "<a id=\"decode_huff\"></a>\n",
    "\n",
    "## decode_huff\n",
    "\n",
    "A partir de uma sequência de bits (mensagem codificada) e uma tabela de huffman, retorne uma mensagem descodificada. A sequência é lida bit a bit, e vão sendo colocados num buffer. Quando a sequência de bits presente no buffer corresponder a um símbolo no dicionário, este é adicionado ao output e o buffer é limpo. O processo repte-se até que todos os bits sejam lidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "continued-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_huff (bit_seq, huff_table):\n",
    "    huff_tree = huff_tree_decode(huff_table)\n",
    "    huff_dictionary = huff_tree2huff_dictionary(huff_tree)\n",
    "    inverted_huff_dictionary = dict(map(reversed, huff_dictionary.items()))\n",
    "    buffer = \"\"\n",
    "    output = []\n",
    "    for bit in bit_seq:\n",
    "        buffer += str(bit)\n",
    "        if buffer in inverted_huff_dictionary:\n",
    "            output.append(inverted_huff_dictionary[buffer])\n",
    "            buffer = \"\"\n",
    "    return bytearray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "outside-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'go go gophers')\n",
      "[0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1\n",
      " 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1]\n",
      "go go gophers\n"
     ]
    }
   ],
   "source": [
    "decoded_msg = decode_huff(biq_seq, encoded_table)\n",
    "print(decoded_msg)\n",
    "print(np.unpackbits(decoded_msg))\n",
    "print((str(decoded_msg, 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-duncan",
   "metadata": {},
   "source": [
    " <a id=\"escrever_ficheiro\"></a>\n",
    "\n",
    "# Escrever para ficheiro\n",
    "\n",
    "A escrita para um ficheiro é conseguida de maneira trivial, gravando primeiro um cabeçalho (tabela seguinte) com informação sobre o a codificação e seguidamente com a mensagem codificada.\n",
    "\n",
    "Byte [index]                       | Info\n",
    ":------------------------------    | :-----------------------------\n",
    "0 - huffman_table_size             | tamanho da tabela de huffman\n",
    "huffman_table_size - huffman_table | huffman \n",
    "huffman_table - data_size          | tamanho da mensagem codificada\n",
    "data_size - eof                    | mensagem codificada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-temple",
   "metadata": {},
   "source": [
    "<a id=\"write2file\"></a>\n",
    "\n",
    "## write2file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "equivalent-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2file(huff_table, bit_seq, filename):\n",
    "    output = np.array([], dtype='uint8')\n",
    "    \n",
    "    # huffman table size\n",
    "    t_size = len(huff_table)\n",
    "    while True:\n",
    "        if(t_size > 255):\n",
    "            output = np.append(output, np.packbits(pad_bits(to_binary_list(255), 8)))\n",
    "            t_size -= 255\n",
    "        else:\n",
    "            output = np.append(output, np.packbits(pad_bits(to_binary_list(t_size), 8)))\n",
    "            break\n",
    "\n",
    "    # huffman table\n",
    "    output = np.append(output, huff_table)\n",
    "    \n",
    "    byte_seq = np.packbits(bit_seq)\n",
    "    # data_size\n",
    "    d_size = (len(byte_seq)*8) - len(bit_seq)\n",
    "    output = np.append(output, np.packbits(pad_bits(to_binary_list(d_size), 8)))\n",
    "            \n",
    "    # data\n",
    "    output = np.append(output, byte_seq)\n",
    "        \n",
    "    np.save(f\"{cwd}/output_data/{filename}\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-community",
   "metadata": {},
   "source": [
    " <a id=\"ler_ficheiro\"></a>\n",
    "\n",
    "# Ler ficheiro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-intake",
   "metadata": {},
   "source": [
    "<a id=\"read2array\"></a>\n",
    "\n",
    "## read2array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ignored-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read2array(filename):\n",
    "    # huffman table size\n",
    "    table_index = 0\n",
    "    table_size = 0\n",
    "    while True:\n",
    "        if(filename[table_index] == 255):\n",
    "            table_size += 255\n",
    "            table_index += 1\n",
    "        else:\n",
    "            table_size += filename[table_index]\n",
    "            break\n",
    "        \n",
    "    # huffman table\n",
    "    huff_table = filename[(table_index + 1):(table_index + table_size + 1)]\n",
    "    \n",
    "    # data size\n",
    "    data_size = filename[(table_index + table_size + 1)]\n",
    "    \n",
    "    # data\n",
    "    byte_seq = filename[(table_index + table_size + 1 + 1):]\n",
    "    # get bit array sequence from byte array\n",
    "    bit_seq = np.unpackbits(byte_seq)\n",
    "   # from the bit sequence we are not interested on the first data_size bits\n",
    "    # so we ignore the rest\n",
    "    bit_seq = bit_seq[:(len(bit_seq)-data_size)]\n",
    "    # return bit sequence with respective huff table\n",
    "    return bit_seq, huff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "physical-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = np.fromfile(f\"{cwd}/intput_data/DecUniversalDH.pdf\", dtype='uint8')\n",
    "\n",
    "huff_table, huff_dictionary = gen_huff_table(test2)\n",
    "bit_seq = encode_huff(test2, huff_dictionary)\n",
    "write2file(huff_table, bit_seq, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "welsh-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_size 10\n",
      "unpack bits:\n",
      " [0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1\n",
      " 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1]\n",
      "go go gophers\n"
     ]
    }
   ],
   "source": [
    "encoded_file = np.load(f\"{cwd}/output_data/test.npy\")\n",
    "encoded_bit_seq, encoded_huff_table = read2array(encoded_file)\n",
    "\n",
    "decoded_byte_seq = decode_huff(encoded_bit_seq, encoded_huff_table)\n",
    "print(\"unpack bits:\\n\", np.unpackbits(decoded_byte_seq))\n",
    "print((str(decoded_byte_seq, 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-lease",
   "metadata": {},
   "source": [
    " <a id=\"testes\"></a>\n",
    "\n",
    "# Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-electronics",
   "metadata": {},
   "source": [
    "## Importar dados para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "final-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file name\n",
    "input_file_name = [\n",
    "    'DecUniversalDH.txt',\n",
    "    'DecUniversalDH.pdf',\n",
    "    'HenryMancini-PinkPanther30s.mp3',\n",
    "    'HenryMancini-PinkPantherC.mid',\n",
    "    'LenaColor.tif',\n",
    "    'LenaGray.tif',\n",
    "]\n",
    "\n",
    "# input file path\n",
    "input_file_path = []\n",
    "for name in input_file_name:\n",
    "    input_file_path.append(f\"{cwd}/intput_data/{name}\")\n",
    "\n",
    "# input file size, bytes\n",
    "input_file_size = []\n",
    "for path in input_file_path:\n",
    "    input_file_size.append(os.stat(path).st_size)\n",
    "    \n",
    "# input file, uint8    \n",
    "input_file = []\n",
    "for path in input_file_path:\n",
    "    input_file.append(np.fromfile(path, dtype='uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-mustang",
   "metadata": {},
   "source": [
    "<a id=\"a\"></a>\n",
    "\n",
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "strong-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecUniversalDH.txt:\n",
      " file size [bytes]: 11930\n",
      " time to create huff table & dictionary [seconds]: 0.011977910995483398\n",
      "\n",
      "DecUniversalDH.pdf:\n",
      " file size [bytes]: 17524\n",
      " time to create huff table & dictionary [seconds]: 0.029887676239013672\n",
      "\n",
      "HenryMancini-PinkPanther30s.mp3:\n",
      " file size [bytes]: 236925\n",
      " time to create huff table & dictionary [seconds]: 0.12866592407226562\n",
      "\n",
      "HenryMancini-PinkPantherC.mid:\n",
      " file size [bytes]: 48049\n",
      " time to create huff table & dictionary [seconds]: 0.034920692443847656\n",
      "\n",
      "LenaColor.tif:\n",
      " file size [bytes]: 786572\n",
      " time to create huff table & dictionary [seconds]: 0.4035792350769043\n",
      "\n",
      "LenaGray.tif:\n",
      " file size [bytes]: 210122\n",
      " time to create huff table & dictionary [seconds]: 0.11670875549316406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "huff_table = []\n",
    "huff_dictionary = []\n",
    "\n",
    "for i in range(len(input_file)):\n",
    "    t_start = time()\n",
    "    ht, hd = gen_huff_table(input_file[i])\n",
    "    t_end = time()\n",
    "    \n",
    "    huff_table.append(ht)\n",
    "    huff_dictionary.append(hd)\n",
    "    \n",
    "    print(f\"{input_file_name[i]}:\")\n",
    "    print(f\" file size [bytes]: {input_file_size[i]}\")\n",
    "    print(f\" time to create huff table & dictionary [seconds]: {t_end - t_start}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-satin",
   "metadata": {},
   "source": [
    "<a id=\"b\"></a>\n",
    "\n",
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-assault",
   "metadata": {},
   "source": [
    "A entropia mede a quantidade de informação codificada na mensagem, onde quando maior for o valor entrópico, maior será a incerteza.\n",
    "\n",
    "A entropia da fonte é dada pela seguinte expressão matemática:\n",
    "\n",
    "$$ H(S) = -\\sum_{i=1}^{N}p(s_i)log_{2}p(s_i) $$\n",
    "\n",
    "\n",
    "A eficiência da condificação pode ser obtida através da seguinte expressão matemática:\n",
    "\n",
    "$$ n = \\frac{H(S)}{L} $$\n",
    "\n",
    "onde, **_L_** é o número médio de bits por símbolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_huffman_entropy(huffman_dictionary):\n",
    "    # the number of events\n",
    "    n = len(huffman_dictionary)\n",
    "    # probability of one event\n",
    "    p = 1.0 / n  # numero de ocr do sym / total \n",
    "    return -sum([p * log2(p) for _ in range(n)])\n",
    "\n",
    "def calculate_huffman_efficiency(entropy, huffman_dictionary):\n",
    "    # average number of bits per symbol\n",
    "    L = 0\n",
    "    for symbol in huffman_dictionary:\n",
    "        L += len(huffman_dictionary[symbol])\n",
    "    L = L / len(huffman_dictionary)\n",
    "    return H / L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(input_file)):\n",
    "    print(f\"{input_file_name[i]}:\")\n",
    "    entropy = calculate_huffman_entropy()\n",
    "    print(f\" entropy: {entropy}\")\n",
    "    efficiency = calculate_huffman_efficiency(entropy, huffman_table[i])\n",
    "    print(f\" efficiency: {efficiency}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-confusion",
   "metadata": {},
   "source": [
    "<a id=\"c\"></a>\n",
    "\n",
    "## c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cleared-count",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecUniversalDH.txt:\n",
      " time to encode message [seconds]: 0.02892160415649414\n",
      "\n",
      "DecUniversalDH.pdf:\n",
      " time to encode message [seconds]: 0.04687237739562988\n",
      "\n",
      "HenryMancini-PinkPanther30s.mp3:\n",
      " time to encode message [seconds]: 0.9028635025024414\n",
      "\n",
      "HenryMancini-PinkPantherC.mid:\n",
      " time to encode message [seconds]: 0.11569476127624512\n",
      "\n",
      "LenaColor.tif:\n",
      " time to encode message [seconds]: 4.811950922012329\n",
      "\n",
      "LenaGray.tif:\n",
      " time to encode message [seconds]: 0.7113895416259766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bit_seq = []\n",
    "\n",
    "for i in range(len(input_file)):\n",
    "    t_start = time()\n",
    "    bs = encode_huff(input_file[i], huff_dictionary[i])\n",
    "    t_end = time()\n",
    "    \n",
    "    bit_seq.append(bs)\n",
    "    \n",
    "    print(f\"{input_file_name[i]}:\")\n",
    "    print(f\" time to encode message [seconds]: {t_end - t_start}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-holmes",
   "metadata": {},
   "source": [
    "<a id=\"d\"></a>\n",
    "\n",
    "## d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "silent-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file name\n",
    "output_file_name = []\n",
    "for i in range(len(input_file)):\n",
    "    write2file(huff_table[i], bit_seq[i], input_file_name[i])\n",
    "    output_file_name.append(f\"{input_file_name[i]}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "sunset-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file path\n",
    "output_file_path = []\n",
    "for name in output_file_name:\n",
    "    output_file_path.append(f\"{cwd}/output_data/{name}\")\n",
    "\n",
    "# output file size, bytes\n",
    "output_file_size = []\n",
    "for path in output_file_path:\n",
    "    output_file_size.append(os.stat(path).st_size)\n",
    "    \n",
    "# output file, uint8    \n",
    "output_file = []\n",
    "for path in output_file_path:\n",
    "    output_file.append(np.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "functional-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecUniversalDH.txt.npy:\n",
      " original file size [bytes]: 11930\n",
      " compressed file size [bytes]: 6851\n",
      " size diference [bytes]: 5079\n",
      " size diference [%]: 74.1351627499635\n",
      "\n",
      "DecUniversalDH.pdf.npy:\n",
      " original file size [bytes]: 17524\n",
      " compressed file size [bytes]: 15932\n",
      " size diference [bytes]: 1592\n",
      " size diference [%]: 9.992467988953058\n",
      "\n",
      "HenryMancini-PinkPanther30s.mp3.npy:\n",
      " original file size [bytes]: 236925\n",
      " compressed file size [bytes]: 237183\n",
      " size diference [bytes]: -258\n",
      " size diference [%]: -0.10877676730626229\n",
      "\n",
      "HenryMancini-PinkPantherC.mid.npy:\n",
      " original file size [bytes]: 48049\n",
      " compressed file size [bytes]: 36523\n",
      " size diference [bytes]: 11526\n",
      " size diference [%]: 31.558196205131004\n",
      "\n",
      "LenaColor.tif.npy:\n",
      " original file size [bytes]: 786572\n",
      " compressed file size [bytes]: 765569\n",
      " size diference [bytes]: 21003\n",
      " size diference [%]: 2.7434496433371702\n",
      "\n",
      "LenaGray.tif.npy:\n",
      " original file size [bytes]: 210122\n",
      " compressed file size [bytes]: 205090\n",
      " size diference [bytes]: 5032\n",
      " size diference [%]: 2.4535569749865926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_file)):\n",
    "    print(f\"{output_file_name[i]}:\")\n",
    "    print(f\" original file size [bytes]: {input_file_size[i]}\")\n",
    "    print(f\" compressed file size [bytes]: {output_file_size[i]}\")\n",
    "    print(f\" size diference [bytes]: {input_file_size[i] - output_file_size[i]}\")\n",
    "    print(f\" size diference [%]: {(input_file_size[i]/output_file_size[i]-1)*100}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-credits",
   "metadata": {},
   "source": [
    "<a id=\"e\"></a>\n",
    "\n",
    "## e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "three-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_bit_seq = []\n",
    "encoded_huff_table = []\n",
    "\n",
    "for i in range(len(output_file)):\n",
    "    ebs, eht = read2array(output_file[i])\n",
    "    encoded_bit_seq.append(ebs)\n",
    "    encoded_huff_table.append(eht)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-edwards",
   "metadata": {},
   "source": [
    "<a id=\"f\"></a>\n",
    "\n",
    "## f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "higher-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecUniversalDH.txt.npy:\n",
      " time to decode message [seconds]: 0.07479691505432129\n",
      "\n",
      "DecUniversalDH.pdf.npy:\n",
      " time to decode message [seconds]: 0.22939085960388184\n",
      "\n",
      "HenryMancini-PinkPanther30s.mp3.npy:\n",
      " time to decode message [seconds]: 2.5424864292144775\n",
      "\n",
      "HenryMancini-PinkPantherC.mid.npy:\n",
      " time to decode message [seconds]: 0.39217090606689453\n",
      "\n",
      "LenaColor.tif.npy:\n",
      " time to decode message [seconds]: 7.9406633377075195\n",
      "\n",
      "LenaGray.tif.npy:\n",
      " time to decode message [seconds]: 2.273927927017212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_message = []\n",
    "\n",
    "for i in range(len(encoded_bit_seq)):\n",
    "    t_start = time()\n",
    "    dm = decode_huff(encoded_bit_seq[i], encoded_huff_table[i])\n",
    "    t_end = time()\n",
    "\n",
    "    decoded_message.append(dm)\n",
    "    \n",
    "    print(f\"{output_file_name[i]}:\")\n",
    "    print(f\" time to decode message [seconds]: {t_end - t_start}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "circular-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'\\nDeclara\\xc3\\xa7\\xc3\\xa3o Universal dos Direitos Humanos\\nPre\\xc3\\xa2mbulo\\n\\nConsiderando que o reconhecimento da dignidade inerente a todos os membros da fam\\xc3\\xadlia humana e dos seus direitos iguais e inalien\\xc3\\xa1veis constitui o fundamento da liberdade, da justi\\xc3\\xa7a e da paz no mundo;\\n\\nConsiderando que o desconhecimento e o desprezo dos direitos do homem conduziram a actos de barb\\xc3\\xa1rie que revoltam a consci\\xc3\\xaancia da Humanidade e que o advento de um mundo em que os seres humanos sejam livres de falar e de crer, libertos do terror e da mis\\xc3\\xa9ria, foi proclamado como a mais alta inspira\\xc3\\xa7\\xc3\\xa3o do homem;\\n\\nConsiderando que \\xc3\\xa9 essencial a protec\\xc3\\xa7\\xc3\\xa3o dos direitos do homem atrav\\xc3\\xa9s de um regime de direito, para que o homem n\\xc3\\xa3o seja compelido, em supremo recurso, \\xc3\\xa0 revolta contra a tirania e a opress\\xc3\\xa3o;\\n\\nConsiderando que \\xc3\\xa9 essencial encorajar o desenvolvimento de rela\\xc3\\xa7\\xc3\\xb5es amistosas entre as na\\xc3\\xa7\\xc3\\xb5es;\\n\\nConsiderando que, na Carta, os povos das Na\\xc3\\xa7\\xc3\\xb5es Unidas proclamam, de novo, a sua f\\xc3\\xa9 nos direitos fundamentais do homem, na dignidade e no valor da pessoa humana, na igualdade de direitos dos homens e das mulheres e se declararam resolvidos a favorecer o progresso social e a instaurar melhores condi\\xc3\\xa7\\xc3\\xb5es de vida dentro de uma liberdade mais ampla;\\n\\nConsiderando que os Estados membros se comprometeram a promover, em coopera\\xc3\\xa7\\xc3\\xa3o com a Organiza\\xc3\\xa7\\xc3\\xa3o das Na\\xc3\\xa7\\xc3\\xb5es Unidas, o respeito universal e efectivo dos direitos do homem e das liberdades fundamentais;\\n\\nConsiderando que uma conce\\xc3\\xa7\\xc3\\xa3o comum destes direitos e liberdades \\xc3\\xa9 da mais alta import\\xc3\\xa2ncia para dar plena satisfa\\xc3\\xa7\\xc3\\xa3o a tal compromisso:\\nA Assembleia Geral\\n\\nProclama a presente Declara\\xc3\\xa7\\xc3\\xa3o Universal dos Direitos do Homem como ideal comum a atingir por todos os povos e todas as na\\xc3\\xa7\\xc3\\xb5es, a fim de que todos os indiv\\xc3\\xadduos e todos os \\xc3\\xb3rg\\xc3\\xa3os da sociedade, tendo-a constantemente no esp\\xc3\\xadrito, se esforcem, pelo ensino e pela educa\\xc3\\xa7\\xc3\\xa3o, por desenvolver o respeito desses direitos e liberdades e por promover, por medidas progressivas de ordem nacional e internacional, o seu reconhecimento e a sua aplica\\xc3\\xa7\\xc3\\xa3o universais e efectivos tanto entre as popula\\xc3\\xa7\\xc3\\xb5es dos pr\\xc3\\xb3prios Estados membros como entre as dos territ\\xc3\\xb3rios colocados sob a sua jurisdi\\xc3\\xa7\\xc3\\xa3o.\\n\\nArtigo 1.\\xc2\\xba\\n\\nTodos os seres humanos nascem livres e iguais em dignidade e em direitos. Dotados de raz\\xc3\\xa3o e de consci\\xc3\\xaancia, devem agir uns para com os outros em esp\\xc3\\xadrito de fraternidade.\\n\\nArtigo 2.\\xc2\\xba\\n\\nTodos os seres humanos podem invocar os direitos e as liberdades proclamados na presente Declara\\xc3\\xa7\\xc3\\xa3o, sem distin\\xc3\\xa7\\xc3\\xa3o alguma, nomeadamente de ra\\xc3\\xa7a, de cor, de sexo, de l\\xc3\\xadngua, de religi\\xc3\\xa3o, de opini\\xc3\\xa3o pol\\xc3\\xadtica ou outra, de origem nacional ou social, de fortuna, de nascimento ou de qualquer outra situa\\xc3\\xa7\\xc3\\xa3o. Al\\xc3\\xa9m disso, n\\xc3\\xa3o ser\\xc3\\xa1 feita nenhuma distin\\xc3\\xa7\\xc3\\xa3o fundada no estatuto pol\\xc3\\xadtico, jur\\xc3\\xaddico ou internacional do pa\\xc3\\xads ou do territ\\xc3\\xb3rio da naturalidade da pessoa, seja esse pa\\xc3\\xads ou territ\\xc3\\xb3rio independente, sob tutela, aut\\xc3\\xb3nomo ou sujeito a alguma limita\\xc3\\xa7\\xc3\\xa3o de soberania.\\n\\nArtigo 3.\\xc2\\xba\\n\\nTodo o indiv\\xc3\\xadduo tem direito \\xc3\\xa0 vida, \\xc3\\xa0 liberdade e \\xc3\\xa0 seguran\\xc3\\xa7a pessoal.\\n\\nArtigo 4.\\xc2\\xba\\n\\nNingu\\xc3\\xa9m ser\\xc3\\xa1 mantido em escravatura ou em servid\\xc3\\xa3o; a escravatura e o trato dos escravos, sob todas as formas, s\\xc3\\xa3o proibidos.\\n\\nArtigo 5.\\xc2\\xba\\n\\nNingu\\xc3\\xa9m ser\\xc3\\xa1 submetido a tortura nem a penas ou tratamentos cru\\xc3\\xa9is, desumanos ou degradantes.\\n\\nArtigo 6.\\xc2\\xba\\n\\nTodos os indiv\\xc3\\xadduos t\\xc3\\xaam direito ao reconhecimento em todos os lugares da sua personalidade jur\\xc3\\xaddica.\\n\\nArtigo 7.\\xc2\\xba\\n\\nTodos s\\xc3\\xa3o iguais perante a lei e, sem distin\\xc3\\xa7\\xc3\\xa3o, t\\xc3\\xaam direito a igual protec\\xc3\\xa7\\xc3\\xa3o da lei. Todos t\\xc3\\xaam direito a protec\\xc3\\xa7\\xc3\\xa3o igual contra qualquer discrimina\\xc3\\xa7\\xc3\\xa3o que viole a presente Declara\\xc3\\xa7\\xc3\\xa3o e contra qualquer incitamento a tal discrimina\\xc3\\xa7\\xc3\\xa3o.\\n\\nArtigo 8.\\xc2\\xba\\n\\nToda a pessoa tem direito a recurso efectivo para as jurisdi\\xc3\\xa7\\xc3\\xb5es nacionais competentes contra os actos que violem os direitos fundamentais reconhecidos pela Constitui\\xc3\\xa7\\xc3\\xa3o ou pela lei.\\n\\nArtigo 9.\\xc2\\xba\\n\\nNingu\\xc3\\xa9m pode ser arbitrariamente preso, detido ou exilado.\\n\\nArtigo 10.\\xc2\\xba\\n\\nToda a pessoa tem direito, em plena igualdade, a que a sua causa seja equitativa e publicamente julgada por um tribunal independente e imparcial que decida dos seus direitos e obriga\\xc3\\xa7\\xc3\\xb5es ou das raz\\xc3\\xb5es de qualquer acusa\\xc3\\xa7\\xc3\\xa3o em mat\\xc3\\xa9ria penal que contra ela seja deduzida.\\n\\nArtigo 11.\\xc2\\xba\\n\\n    Toda a pessoa acusada de um acto delituoso presume-se inocente at\\xc3\\xa9 que a sua culpabilidade fique legalmente provada no decurso de um processo p\\xc3\\xbablico em que todas as garantias necess\\xc3\\xa1rias de defesa lhe sejam asseguradas.\\n    Ningu\\xc3\\xa9m ser\\xc3\\xa1 condenado por ac\\xc3\\xa7\\xc3\\xb5es ou omiss\\xc3\\xb5es que, no momento da sua pr\\xc3\\xa1tica, n\\xc3\\xa3o constitu\\xc3\\xadam acto delituoso \\xc3\\xa0 face do direito interno ou internacional. Do mesmo modo, n\\xc3\\xa3o ser\\xc3\\xa1 infligida pena mais grave do que a que era aplic\\xc3\\xa1vel no momento em que o acto delituoso foi cometido.\\n\\nArtigo 12.\\xc2\\xba\\n\\nNingu\\xc3\\xa9m sofrer\\xc3\\xa1 intromiss\\xc3\\xb5es arbitr\\xc3\\xa1rias na sua vida privada, na sua fam\\xc3\\xadlia, no seu domic\\xc3\\xadlio ou na sua correspond\\xc3\\xaancia, nem ataques \\xc3\\xa0 sua honra e reputa\\xc3\\xa7\\xc3\\xa3o. Contra tais intromiss\\xc3\\xb5es ou ataques toda a pessoa tem direito a protec\\xc3\\xa7\\xc3\\xa3o da lei.\\n\\nArtigo 13.\\xc2\\xba\\n\\n    Toda a pessoa tem o direito de livremente circular e escolher a sua resid\\xc3\\xaancia no interior de um Estado.\\n    Toda a pessoa tem o direito de abandonar o pa\\xc3\\xads em que se encontra, incluindo o seu, e o direito de regressar ao seu pa\\xc3\\xads.\\n\\nArtigo 14.\\xc2\\xba\\n\\n    Toda a pessoa sujeita a persegui\\xc3\\xa7\\xc3\\xa3o tem o direito de procurar e de beneficiar de asilo em outros pa\\xc3\\xadses.\\n    Este direito n\\xc3\\xa3o pode, por\\xc3\\xa9m, ser invocado no caso de processo realmente existente por crime de direito comum ou por actividades contr\\xc3\\xa1rias aos fins e aos princ\\xc3\\xadpios das Na\\xc3\\xa7\\xc3\\xb5es Unidas.\\n\\nArtigo 15.\\xc2\\xba\\n\\n    Todo o indiv\\xc3\\xadduo tem direito a ter uma nacionalidade.\\n    Ningu\\xc3\\xa9m pode ser arbitrariamente privado da sua nacionalidade nem do direito de mudar de nacionalidade.\\n\\nArtigo 16.\\xc2\\xba\\n\\n    A partir da idade n\\xc3\\xbabil, o homem e a mulher t\\xc3\\xaam o direito de casar e de constituir fam\\xc3\\xadlia, sem restri\\xc3\\xa7\\xc3\\xa3o alguma de ra\\xc3\\xa7a, nacionalidade ou religi\\xc3\\xa3o. Durante o casamento e na altura da sua dissolu\\xc3\\xa7\\xc3\\xa3o, ambos t\\xc3\\xaam direitos iguais.\\n    O casamento n\\xc3\\xa3o pode ser celebrado sem o livre e pleno consentimento dos futuros esposos.\\n    A fam\\xc3\\xadlia \\xc3\\xa9 o elemento natural e fundamental da sociedade e tem direito \\xc3\\xa0 protec\\xc3\\xa7\\xc3\\xa3o desta e do Estado.\\n\\nArtigo 17.\\xc2\\xba\\n\\n    Toda a pessoa, individual ou colectivamente, tem direito \\xc3\\xa0 propriedade.\\n    Ningu\\xc3\\xa9m pode ser arbitrariamente privado da sua propriedade.\\n\\nArtigo 18.\\xc2\\xba\\n\\nToda a pessoa tem direito \\xc3\\xa0 liberdade de pensamento, de consci\\xc3\\xaancia e de religi\\xc3\\xa3o; este direito implica a liberdade de mudar de religi\\xc3\\xa3o ou de convic\\xc3\\xa7\\xc3\\xa3o, assim como a liberdade de manifestar a religi\\xc3\\xa3o ou convic\\xc3\\xa7\\xc3\\xa3o, sozinho ou em comum, tanto em p\\xc3\\xbablico como em privado, pelo ensino, pela pr\\xc3\\xa1tica, pelo culto e pelos ritos.\\n\\nArtigo 19.\\xc2\\xba\\n\\nTodo o indiv\\xc3\\xadduo tem direito \\xc3\\xa0 liberdade de opini\\xc3\\xa3o e de express\\xc3\\xa3o, o que implica o direito de n\\xc3\\xa3o ser inquietado pelas suas opini\\xc3\\xb5es e o de procurar, receber e difundir, sem considera\\xc3\\xa7\\xc3\\xa3o de fronteiras, informa\\xc3\\xa7\\xc3\\xb5es e ideias por qualquer meio de express\\xc3\\xa3o.\\n\\nArtigo 20.\\xc2\\xba\\n\\n    Toda a pessoa tem direito \\xc3\\xa0 liberdade de reuni\\xc3\\xa3o e de associa\\xc3\\xa7\\xc3\\xa3o pac\\xc3\\xadficas.\\n    Ningu\\xc3\\xa9m pode ser obrigado a fazer parte de uma associa\\xc3\\xa7\\xc3\\xa3o.\\n\\nArtigo 21.\\xc2\\xba\\n\\n    Toda a pessoa tem o direito de tomar parte na direc\\xc3\\xa7\\xc3\\xa3o dos neg\\xc3\\xb3cios p\\xc3\\xbablicos do seu pa\\xc3\\xads, quer directamente, quer por interm\\xc3\\xa9dio de representantes livremente escolhidos.\\n    Toda a pessoa tem direito de acesso, em condi\\xc3\\xa7\\xc3\\xb5es de igualdade, \\xc3\\xa0s fun\\xc3\\xa7\\xc3\\xb5es p\\xc3\\xbablicas do seu pa\\xc3\\xads.\\n    A vontade do povo \\xc3\\xa9 o fundamento da autoridade dos poderes p\\xc3\\xbablicos; e deve exprimir-se atrav\\xc3\\xa9s de elei\\xc3\\xa7\\xc3\\xb5es honestas a realizar periodicamente por sufr\\xc3\\xa1gio universal e igual, com voto secreto ou segundo processo equivalente que salvaguarde a liberdade de voto.\\n\\nArtigo 22.\\xc2\\xba\\n\\nToda a pessoa, como membro da sociedade, tem direito \\xc3\\xa0 seguran\\xc3\\xa7a social; e pode legitimamente exigir a satisfa\\xc3\\xa7\\xc3\\xa3o dos direitos econ\\xc3\\xb3micos, sociais e culturais indispens\\xc3\\xa1veis, gra\\xc3\\xa7as ao esfor\\xc3\\xa7o nacional e \\xc3\\xa0 coopera\\xc3\\xa7\\xc3\\xa3o internacional, de harmonia com a organiza\\xc3\\xa7\\xc3\\xa3o e os recursos de cada pa\\xc3\\xads.\\n\\nArtigo 23.\\xc2\\xba\\n\\n    Toda a pessoa tem direito ao trabalho, \\xc3\\xa0 livre escolha do trabalho, a condi\\xc3\\xa7\\xc3\\xb5es equitativas e satisfat\\xc3\\xb3rias de trabalho e \\xc3\\xa0 protec\\xc3\\xa7\\xc3\\xa3o contra o desemprego.\\n    Todos t\\xc3\\xaam direito, sem discrimina\\xc3\\xa7\\xc3\\xa3o alguma, a sal\\xc3\\xa1rio igual por trabalho igual.\\n    Quem trabalha tem direito a uma remunera\\xc3\\xa7\\xc3\\xa3o equitativa e satisfat\\xc3\\xb3ria, que lhe permita e \\xc3\\xa0 sua fam\\xc3\\xadlia uma exist\\xc3\\xaancia conforme com a dignidade humana, e completada, se poss\\xc3\\xadvel, por todos os outros meios de protec\\xc3\\xa7\\xc3\\xa3o social.\\n    Toda a pessoa tem o direito de fundar com outras pessoas sindicatos e de se filiar em sindicatos para a defesa dos seus interesses.\\n\\nArtigo 24.\\xc2\\xba\\n\\nToda a pessoa tem direito ao repouso e aos lazeres e, especialmente, a uma limita\\xc3\\xa7\\xc3\\xa3o razo\\xc3\\xa1vel da dura\\xc3\\xa7\\xc3\\xa3o do trabalho e a f\\xc3\\xa9rias peri\\xc3\\xb3dicas pagas.\\n\\nArtigo 25.\\xc2\\xba\\n\\n    Toda a pessoa tem direito a um n\\xc3\\xadvel de vida suficiente para lhe assegurar e \\xc3\\xa0 sua fam\\xc3\\xadlia a sa\\xc3\\xbade e o bem-estar, principalmente quanto \\xc3\\xa0 alimenta\\xc3\\xa7\\xc3\\xa3o, ao vestu\\xc3\\xa1rio, ao alojamento, \\xc3\\xa0 assist\\xc3\\xaancia m\\xc3\\xa9dica e ainda quanto aos servi\\xc3\\xa7os sociais necess\\xc3\\xa1rios, e tem direito \\xc3\\xa0 seguran\\xc3\\xa7a no desemprego, na doen\\xc3\\xa7a, na invalidez, na viuvez, na velhice ou noutros casos de perda de meios de subsist\\xc3\\xaancia por circunst\\xc3\\xa2ncias independentes da sua vontade.\\n    A maternidade e a inf\\xc3\\xa2ncia t\\xc3\\xaam direito a ajuda e a assist\\xc3\\xaancia especiais. Todas as crian\\xc3\\xa7as, nascidas dentro ou fora do matrim\\xc3\\xb3nio, gozam da mesma protec\\xc3\\xa7\\xc3\\xa3o social.\\n\\nArtigo 26.\\xc2\\xba\\n\\n    Toda a pessoa tem direito \\xc3\\xa0 educa\\xc3\\xa7\\xc3\\xa3o. A educa\\xc3\\xa7\\xc3\\xa3o deve ser gratuita, pelo menos a correspondente ao ensino elementar fundamental. O ensino elementar \\xc3\\xa9 obrigat\\xc3\\xb3rio. O ensino t\\xc3\\xa9cnico e profissional deve ser generalizado; o acesso aos estudos superiores deve estar aberto a todos em plena igualdade, em fun\\xc3\\xa7\\xc3\\xa3o do seu m\\xc3\\xa9rito.\\n    A educa\\xc3\\xa7\\xc3\\xa3o deve visar \\xc3\\xa0 plena expans\\xc3\\xa3o da personalidade humana e ao refor\\xc3\\xa7o dos direitos do homem e das liberdades fundamentais e deve favorecer a compreens\\xc3\\xa3o, a toler\\xc3\\xa2ncia e a amizade entre todas as na\\xc3\\xa7\\xc3\\xb5es e todos os grupos raciais ou religiosos, bem como o desenvolvimento das actividades das Na\\xc3\\xa7\\xc3\\xb5es Unidas para a manuten\\xc3\\xa7\\xc3\\xa3o da paz.\\n    Aos pais pertence a prioridade do direito de escolher o g\\xc3\\xa9nero de educa\\xc3\\xa7\\xc3\\xa3o a dar aos filhos.\\n\\nArtigo 27.\\xc2\\xba\\n\\n    Toda a pessoa tem o direito de tomar parte livremente na vida cultural da comunidade, de fruir as artes e de participar no progresso cient\\xc3\\xadfico e nos benef\\xc3\\xadcios que deste resultam.\\n    Todos t\\xc3\\xaam direito \\xc3\\xa0 protec\\xc3\\xa7\\xc3\\xa3o dos interesses morais e materiais ligados a qualquer produ\\xc3\\xa7\\xc3\\xa3o cient\\xc3\\xadfica, liter\\xc3\\xa1ria ou art\\xc3\\xadstica da sua autoria.\\n\\nArtigo 28.\\xc2\\xba\\n\\nToda a pessoa tem direito a que reine, no plano social e no plano internacional, uma ordem capaz de tornar plenamente efectivos os direitos e as liberdades enunciados na presente Declara\\xc3\\xa7\\xc3\\xa3o.\\n\\nArtigo 29.\\xc2\\xba\\n\\n    O indiv\\xc3\\xadduo tem deveres para com a comunidade, fora da qual n\\xc3\\xa3o \\xc3\\xa9 poss\\xc3\\xadvel o livre e pleno desenvolvimento da sua personalidade.\\n    No exerc\\xc3\\xadcio destes direitos e no gozo destas liberdades ningu\\xc3\\xa9m est\\xc3\\xa1 sujeito sen\\xc3\\xa3o \\xc3\\xa0s limita\\xc3\\xa7\\xc3\\xb5es estabelecidas pela lei com vista exclusivamente a promover o reconhecimento e o respeito dos direitos e liberdades dos outros e a fim de satisfazer as justas exig\\xc3\\xaancias da moral, da ordem p\\xc3\\xbablica e do bem-estar numa sociedade democr\\xc3\\xa1tica.\\n    Em caso algum estes direitos e liberdades poder\\xc3\\xa3o ser exercidos contrariamente aos fins e aos princ\\xc3\\xadpios das Na\\xc3\\xa7\\xc3\\xb5es Unidas.\\n\\nArtigo 30.\\xc2\\xba\\n\\nNenhuma disposi\\xc3\\xa7\\xc3\\xa3o da presente Declara\\xc3\\xa7\\xc3\\xa3o pode ser interpretada de maneira a envolver para qualquer Estado, agrupamento ou indiv\\xc3\\xadduo o direito de se entregar a alguma actividade ou de praticar algum acto destinado a destruir os direitos e liberdades aqui enunciados.\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "print(decoded_message[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-degree",
   "metadata": {},
   "source": [
    "<a id=\"g\"></a>\n",
    "\n",
    "## g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "spread-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:\n",
      " [0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(input_file)):\n",
    "    error.append(np.sum(np.subtract(input_file[i], decoded_message[i])))\n",
    "print(\"error:\\n\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-colonial",
   "metadata": {},
   "source": [
    "<a id=\"conclusoes\"></a>\n",
    "\n",
    "# Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-islam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csm_env",
   "language": "python",
   "name": "csm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
